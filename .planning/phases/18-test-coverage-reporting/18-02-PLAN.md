---
phase: 18-test-coverage-reporting
plan: 02
type: execute
wave: 2
depends_on: ["18-01"]
files_modified:
  - src/WsusManager.Tests/Services/DatabaseBackupServiceTests.cs
  - src/WsusManager.Tests/Services/ExportServiceTests.cs
  - src/WsusManager.Tests/Services/ImportServiceTests.cs
  - src/WsusManager.Tests/Services/ContentResetServiceTests.cs
  - src/WsusManager.Tests/Services/ClientServiceTests.cs
  - src/WsusManager.Tests/Foundation/OperationResultTests.cs
autonomous: true
requirements:
  - TEST-05
user_setup: []

must_haves:
  truths:
    - "Null inputs throw ArgumentNullException in public service methods"
    - "Empty collections are handled correctly without crashes"
    - "Boundary values (0, -1, int.MaxValue) are tested"
    - "Coverage report shows improved coverage after edge case tests added"
  artifacts:
    - path: "src/WsusManager.Tests/Services/*/Tests.cs"
      provides: "Edge case tests for service layer"
      contains: "Theory", "InlineData", "ArgumentNullException"
    - path: "src/WsusManager.Tests/Foundation/*Tests.cs"
      provides: "Edge case tests for foundation types"
      contains: "null", "empty", "Theory"
  key_links:
    - from: "Test methods"
      to: "Production service methods"
      via: "Null argument tests verify defensive programming"
      pattern: "Throws.*ArgumentNullException"
    - from: "Coverage report"
      to: "Improved line/branch coverage"
      via: "Edge case tests exercising previously untested paths"
      pattern: "coverage.*increase"
---

<objective>
Add edge case tests for null inputs, empty collections, and boundary values across service and foundation layers. Focus on public service methods that handle external data (file paths, SQL inputs, WinRM responses) and core types used throughout the application.

Purpose: Ensure robust handling of edge cases that commonly cause runtime exceptions in production
Output: Expanded test suite with explicit edge case coverage, measurable coverage increase
</objective>

<execution_context>
@/home/anthonyscry/.claude/get-shit-done/workflows/execute-plan.md
@/home/anthonyscry/.claude/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/phases/18-test-coverage-reporting/18-CONTEXT.md
@.planning/phases/18-test-coverage-reporting/18-RESEARCH.md
@.planning/phases/18-test-coverage-reporting/18-01-SUMMARY.md
@src/WsusManager.Tests/Services/HealthServiceTests.cs
@src/WsusManager.Core/Services/Interfaces/*.cs
</context>

<tasks>

<task type="auto">
  <name>Audit existing tests for missing edge case coverage</name>
  <files>src/WsusManager.Tests/Services/*Tests.cs</files>
  <action>
Audit all service test files for missing edge case tests. For each test file, check:

1. **Null input tests**: Look for `Assert.ThrowsAsync<ArgumentNullException>` or similar patterns
2. **Empty collection tests**: Look for tests passing empty arrays, lists, or strings
3. **Boundary value tests**: Look for `Theory` with `InlineData` for 0, -1, max values

Create an audit list in comments at the top of each file that needs edge case additions:
```csharp
// EDGE CASE AUDIT (Phase 18-02):
// [ ] Null input: MethodName(string input) - missing
// [ ] Empty: ProcessItems(string[] items) - missing
// [x] Boundary: GetValue(int index) - has Theory with 0, -1, Max
```

Prioritize services that handle external data:
- DatabaseBackupService (file paths, SQL inputs)
- ExportService/ImportService (file paths, directory paths)
- ContentResetService (file paths)
- ClientService (WinRM inputs, computer names)
- OperationResult (foundational type, used everywhere)

Do NOT modify test implementations yet - just document what's missing.
  </action>
  <verify>
Run `grep -r "EDGE CASE AUDIT" src/WsusManager.Tests/` and verify:
1. At least 6 service test files have audit comments
2. Each audit lists 3-10 missing edge case tests
3. Audit identifies specific methods needing tests
  </verify>
  <done>
All service test files audited with documented missing edge case tests prioritized by risk (external data handlers first)
  </done>
</task>

<task type="auto">
  <name>Add null input tests to high-risk service methods</name>
  <files>
    src/WsusManager.Tests/Services/DatabaseBackupServiceTests.cs
    src/WsusManager.Tests/Services/ExportServiceTests.cs
    src/WsusManager.Tests/Services/ImportServiceTests.cs
  </files>
  <action>
Add null input tests for public methods in DatabaseBackupService, ExportService, and ImportService.

For each service, identify public methods accepting string or collection parameters and add tests like:

```csharp
[Fact]
public async Task BackupAsync_Throws_When_ContentPath_Is_Null()
{
    await Assert.ThrowsAsync<ArgumentNullException>(
        () => _service.BackupAsync(null!, @"C:\backup"));
}

[Fact]
public async Task BackupAsync_Throws_When_BackupPath_Is_Null()
{
    await Assert.ThrowsAsync<ArgumentNullException>(
        () => _service.BackupAsync(@"C:\WSUS", null!));
}

[Fact]
public async Task ExportAsync_Throws_When_ExportPath_Is_Null()
{
    await Assert.ThrowsAsync<ArgumentNullException>(
        () => _service.ExportAsync(null!, true, _progress));
}
```

Follow existing test patterns in the file (mock setup, service creation pattern). Add tests at the end of each test class in a new "Edge Cases" region with comment:
```csharp
// ─── Edge Case Tests (Phase 18-02) ───────────────────────────────────
```

Target: 10-15 new null input tests across the 3 services.
  </action>
  <verify>
Run `dotnet test src/WsusManager.Tests/WsusManager.Tests.csproj --filter "FullyQualifiedName~DatabaseBackupServiceTests" --configuration Release` and verify:
1. All existing tests still pass
2. New null input tests pass (throwing ArgumentNullException as expected)
3. Test count increased by expected number

Repeat for ExportServiceTests and ImportServiceTests.
  </verify>
  <done>
High-risk file I/O services have comprehensive null input validation tests ensuring ArgumentNullException thrown for all null parameters
  </done>
</task>

<task type="auto">
  <name>Add empty collection and boundary value tests</name>
  <files>
    src/WsusManager.Tests/Services/ContentResetServiceTests.cs
    src/WsusManager.Tests/Services/ClientServiceTests.cs
    src/WsusManager.Tests/Foundation/OperationResultTests.cs
  </files>
  <action>
Add empty collection and boundary value tests for ContentResetService, ClientService, and OperationResult.

**Empty collection tests** (services processing lists/arrays):
```csharp
[Fact]
public async Task CheckMultipleClientsAsync_Returns_Empty_When_ComputerNames_Is_Empty()
{
    var result = await _service.CheckMultipleClientsAsync([], _progress);

    Assert.Empty(result);
}
```

**Boundary value tests** (using Theory/InlineData):
```csharp
[Theory]
[InlineData(0)]
[InlineData(-1)]
[InlineData(int.MaxValue)]
public void OperationResult_Handles_Boundary_Codes(int code)
{
    var result = OperationResult.Fail("Test", code);

    Assert.Equal(code, result.ErrorCode);
}
```

For ClientService, add WinRM input edge cases:
```csharp
[Theory]
[InlineData("")]
[InlineData("   ")]
[InlineData("INVALID\\COMPUTER/NAME")]
public async Task CheckClientAsync_Handles_Invalid_ComputerNames(string computerName)
{
    var result = await _service.CheckClientAsync(computerName);

    Assert.False(result.IsSuccess); // or specific error handling
}
```

Add tests in "Edge Cases" region at end of each test class. Target: 10-15 new tests across the 3 classes.
  </action>
  <verify>
Run `dotnet test src/WsusManager.Tests/WsusManager.Tests.csproj --configuration Release` and verify:
1. All existing tests still pass
2. New edge case tests pass
3. Tests use `[Theory]` and `[InlineData]` appropriately for boundary values
4. Empty collection tests don't crash (handle gracefully)

Check test output for coverage increase (if coverage tools installed).
  </verify>
  <done>
Services handle empty collections and boundary values correctly with explicit test coverage for edge case scenarios
  </done>
</task>

</tasks>

<verification>
## Post-Execution Verification

### Coverage Measurement
1. Run `dotnet test --settings src/coverlet.runsettings --collect:"XPlat Code Coverage"`
2. Run `reportgenerator` to generate HTML report
3. Open coverage report and verify:
   - Line coverage increased from baseline (Plan 01)
   - Branch coverage improved (edge cases often add branch coverage)
   - Previously untested methods now have coverage

### Test Quality
1. Review new edge case tests in each modified file
2. Verify: Tests follow existing patterns (mock setup, assertions)
3. Verify: Each test has clear name indicating what edge case it tests
4. Verify: No tests are skipped or marked with `Skip` attribute

### Documentation
1. Check that audit comments were added to test files
2. Verify: Audit comments accurately reflect what tests were added
3. Update SUMMARY.md with count of edge case tests added
</verification>

<success_criteria>
## Phase 18 Success Criteria (Partial)

From this plan:
- [x] Edge cases (null inputs, empty collections, boundary values) are explicitly tested

Combined with Plan 01:
- [x] Coverage report includes both line coverage percentage and branch coverage analysis

Remaining criteria (Plan 03):
- [ ] All exception handling paths have corresponding test coverage
</success_criteria>

<output>
After completion, create `.planning/phases/18-test-coverage-reporting/18-02-SUMMARY.md` documenting:
1. Number of edge case tests added (by category: null, empty, boundary)
2. Coverage increase measured (line % and branch % before/after)
3. List of services/files that received edge case tests
4. Any edge cases discovered but not tested (technical blockers, etc.)
</output>
