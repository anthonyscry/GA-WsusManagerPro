---
phase: 22-performance-benchmarking
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/WsusManager.sln
  - src/WsusManager.Benchmarks/WsusManager.Benchmarks.csproj
  - src/BenchmarkDotNet.Artifacts/
  - .gitignore
autonomous: true
requirements:
  - PERF-01
  - PERF-02
user_setup: []

must_haves:
  truths:
    - "BenchmarkDotNet project is created and added to solution"
    - "Developer can run benchmarks locally via `dotnet run -c Release`"
    - "Benchmark results generate HTML reports with statistical analysis"
    - "Baseline results are captured and stored in repository"
  artifacts:
    - path: "src/WsusManager.Benchmarks/WsusManager.Benchmarks.csproj"
      provides: "Benchmark project configuration (BenchmarkDotNet reference, output path)"
      contains: "BenchmarkDotNet"
    - path: "src/WsusManager.Benchmarks/BenchmarkStartup.cs"
      provides: "Cold/warm startup benchmark implementation"
      contains: "Benchmark"
    - path: "src/WsusManager.sln"
      provides: "Solution file updated to include benchmarks project"
      contains: "WsusManager.Benchmarks"
  key_links:
    - from: "dotnet run -c Release -p:NoBuild=true"
      to: "BenchmarkDotNet.Artifacts/results.html"
      via: "Benchmark execution and report generation"
      pattern: "BenchmarkDotNet\\..*Artifacts"
---

<objective>
Create a separate BenchmarkDotNet performance testing project with startup time benchmarks. Establish the infrastructure for measuring cold/warm startup performance, generating HTML reports with statistical analysis, and capturing baseline measurements. Integrate project into solution for easy local benchmark execution.

Purpose: Enable data-driven performance tracking for critical operations with statistical rigor
Output: Working benchmark project with startup baselines documented
</objective>

<execution_context>
@/home/anthonyscry/.claude/get-shit-done/workflows/execute-plan.md
@/home/anthonyscry/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/phases/22-performance-benchmarking/22-CONTEXT.md
@src/WsusManager.sln
@src/WsusManager.App/WsusManager.App.csproj
@src/WsusManager.Core/WsusManager.Core.csproj
@.github/workflows/build-csharp.yml
</context>

<tasks>

<task type="auto">
  <name>Create BenchmarkDotNet project and add to solution</name>
  <files>src/WsusManager.Benchmarks/WsusManager.Benchmarks.csproj, src/WsusManager.sln</files>
  <action>
Create a new console application project `src/WsusManager.Benchmarks/WsusManager.Benchmarks.csproj` with the following configuration:

1. **Create directory:** `src/WsusManager.Benchmarks/`
2. **Create csproj file** with:
   - `OutputType`: `Exe`
   - `TargetFramework`: `net8.0`
   - `ImplicitUsings`: `enable`
   - `Nullable`: `enable`
   - `IsPackable`: `false` (not a NuGet package)
   - Package reference: `BenchmarkDotNet` version `0.14.0`
   - Project reference: `../WsusManager.App/WsusManager.App.csproj`

3. **Create Program.cs** with:
   - `using BenchmarkDotNet.Running;`
   - `using BenchmarkDotNet.Attributes;`
   - Simple entry point: `BenchmarkSwitcher.FromAssembly(typeof(Program).Assembly).Run(args);`

4. **Add to solution:** Run `dotnet sln src/WsusManager.sln add src/WsusManager.Benchmarks/WsusManager.Benchmarks.csproj`

The benchmark project should be completely standalone and not interfere with normal build/test execution.
  </action>
  <verify>
Run the following commands and verify:
1. `dotnet build src/WsusManager.Benchmarks/WsusManager.Benchmarks.csproj` compiles successfully
2. `dotnet sln src/WsusManager.sln list` includes `WsusManager.Benchmarks/WsusManager.Benchmarks.csproj`
3. `dotnet run --project src/WsusManager.Benchmarks/WsusManager.Benchmarks.csproj -c Release` shows BenchmarkDotNet banner (no benchmarks yet, but infrastructure works)
  </verify>
  <done>
Benchmark project compiles and runs, showing BenchmarkDotNet banner with valid infrastructure
</done>
</task>

<task type="auto">
  <name>Create startup performance benchmark (cold/warm)</name>
  <files>src/WsusManager.Benchmarks/BenchmarkStartup.cs</files>
  <action>
Create `src/WsusManager.Benchmarks/BenchmarkStartup.cs` with startup time benchmarks.

**Class structure:**
```csharp
using BenchmarkDotNet.Attributes;
using BenchmarkDotNet.Configs;
using BenchmarkDotNet.Diagnosers;
using BenchmarkDotNet.Engines;
using BenchmarkDotNet.Jobs;
using System.Diagnostics;

[MemoryDiagnoser]
[SimpleJob(warmupCount: 100, iterationCount: 1000)]
[HtmlExporter]
[CsvExporter]
[RPlotExporter]
public class BenchmarkStartup
{
    private Process _process;

    [GlobalSetup]
    public void Setup()
    {
        // Build the app once before benchmarking
        var buildInfo = new ProcessStartInfo
        {
            FileName = "dotnet",
            Arguments = "build src/WsusManager.App/WsusManager.App.csproj --configuration Release",
            UseShellExecute = false,
            CreateNoWindow = true
        };
        using var build = Process.Start(buildInfo);
        build?.WaitForExit();
    }

    [GlobalCleanup]
    public void Cleanup()
    {
        _process?.Kill();
        _process?.Dispose();
    }

    [Benchmark]
    [Benchmark("NET8", "Cold startup time (first launch)")]
    public void ColdStartup()
    {
        // Measure time to launch EXE from scratch
        var exePath = "src/WsusManager.App/bin/Release/net8.0/win-x64/publish/WsusManager.App.exe";
        if (!File.Exists(exePath))
        {
            exePath = "src/WsusManager.App/bin/Release/net8.0/WsusManager.App.dll";
        }

        var startInfo = new ProcessStartInfo
        {
            FileName = exePath,
            UseShellExecute = false,
            CreateNoWindow = true,
            RedirectStandardOutput = true
        };

        var sw = Stopwatch.StartNew();
        using var proc = Process.Start(startInfo);
        // Wait for initialization - kill after 2s max
        proc?.WaitForExit(2000);
        if (proc != null && !proc.HasExited)
        {
            proc.Kill();
        }
        sw.Stop();

        // Result is the elapsed time
        _ = sw.ElapsedMilliseconds; // Consume to avoid optimization
    }

    [Benchmark]
    [Benchmark("NET8", "Warm startup time (subsequent launch)")]
    public void WarmStartup()
    {
        // Same as cold but called repeatedly (BenchmarkDotNet handles this)
        ColdStartup();
    }
}
```

Note: This is a simplified startup benchmark. Real startup measurement requires more sophisticated process lifecycle management. The key is establishing the pattern - CI will capture actual timing data.
  </action>
  <verify>
Run `dotnet run --project src/WsusManager.Benchmarks/WsusManager.Benchmarks.csproj -c Release` and verify:
1. Benchmarks execute without crashing
2. Output shows "BenchmarkDotNet.Artifacts" directory creation
3. Results display with Mean, StdDev, and other statistics
4. HTML report is generated in `BenchmarkDotNet.Artifacts/results.html`
  </verify>
  <done>
Startup benchmark runs successfully and generates HTML report with timing statistics
</done>
</task>

<task type="auto">
  <name>Configure benchmark output and gitignore</name>
  <files>.gitignore</files>
  <action>
Update `.gitignore` to exclude benchmark artifacts (don't commit generated reports).

Add these entries:
- `# Benchmark artifacts`
- `**/BenchmarkDotNet.Artifacts/`
- `*.benchmark.csv`
- `*.benchmark.r`
- `*-benchmark.csv`
- `*-report.csv`

These patterns exclude all BenchmarkDotNet generated files. We want to keep the benchmark code in the repository but not the generated reports (those go in CI artifacts).
  </action>
  <verify>
1. Run `git status` and verify no BenchmarkDotNet.Artifacts directories show as untracked
2. Create a dummy `BenchmarkDotNet.Artifacts` directory and verify it's ignored
3. Verify only `.gitignore` and benchmark source files show as changes
  </verify>
  <done>
Benchmark artifacts are excluded from version control while benchmark code remains tracked
</done>
</task>

<task type="auto">
  <name>Capture baseline startup measurements</name>
  <files>src/WsusManager.Benchmarks/baselines/</files>
  <action>
Run benchmarks locally to capture baseline measurements:

1. **Build Release configuration:**
   ```bash
   dotnet build src/WsusManager.App/WsusManager.App.csproj --configuration Release
   dotnet build src/WsusManager.Benchmarks/WsusManager.Benchmarks.csproj --configuration Release
   ```

2. **Run benchmarks:**
   ```bash
   cd src/WsusManager.Benchmarks
   dotnet run -c Release --configuration Release
   ```

3. **Create baselines directory:** `src/WsusManager.Benchmarks/baselines/`

4. **Copy baseline results:**
   - Copy `BenchmarkDotNet.Artifacts/results-BenchmarkStartup-report.html` to `baselines/startup-baseline.html`
   - Copy `BenchmarkDotNet.Artifacts/results-BenchmarkStartup-report.csv` to `baselines/startup-baseline.csv`

5. **Document baseline values:** Create `baselines/README.md` with:
   - Cold startup mean time (ms)
   - Warm startup mean time (ms)
   - Benchmark run date
   - Hardware info (capture from BenchmarkDotNet output)
   - .NET version

The baseline files will be checked into the repository as the performance standard. Future runs will compare against these values.
  </action>
  <verify>
1. Verify `src/WsusManager.Benchmarks/baselines/startup-baseline.html` exists
2. Open CSV and extract Mean values for ColdStartup and WarmStartup
3. Verify baseline README documents actual measurements
4. Run `git status` - baselines should show as new files to commit
  </verify>
  <done>
Baseline startup measurements captured and documented in repository with mean times recorded
</done>
</task>

</tasks>

<verification>
## Post-Execution Verification

### Local Benchmark Execution
1. Run `dotnet run --project src/WsusManager.Benchmarks/WsusManager.Benchmarks.csproj -c Release`
2. Verify benchmark completes with statistical output (Mean, StdDev, Min, Max)
3. Open `BenchmarkDotNet.Artifacts/results.html` - verify report loads
4. Check `baselines/startup-baseline.csv` contains numeric timing data

### Solution Integration
1. Run `dotnet build src/WsusManager.sln` - verify benchmarks project builds with solution
2. Run `dotnet test src/WsusManager.sln` - verify benchmarks don't interfere with normal tests
3. Check `dotnet sln list` - verify WsusManager.Benchmarks is included

### Baseline Capture
1. Open `baselines/startup-baseline.html` - verify visual report
2. Open `baselines/README.md` - verify documented mean times
3. Verify baseline files are ready for commit (not in .gitignore)
</verification>

<success_criteria>
## Phase 22 Success Criteria (Partial - Plan 01)

From this plan:
- [x] BenchmarkDotNet project is created and added to solution
- [x] Developer can run benchmarks locally via `dotnet run -c Release`
- [x] Benchmark results generate HTML reports with statistical analysis
- [x] Baseline startup results are captured and stored in repository
- [x] Startup time is measured (cold/warm) with documented baselines

Remaining criteria (Plans 02-03):
- [ ] Database operations have baseline performance metrics
- [ ] WinRM operations have baseline performance metrics
- [ ] CI/CD pipeline displays benchmarks in build output
- [ ] Performance regressions are detected before release
</success_criteria>

<output>
After completion, create `.planning/phases/22-performance-benchmarking/22-01-SUMMARY.md` documenting:
1. Actual baseline startup times (cold and warm) in milliseconds
2. BenchmarkDotNet version installed (should be 0.14.0)
3. Number of iterations configured (warmup/measurement counts)
4. Any challenges with process lifecycle management during benchmarking
5. Path to baseline HTML report (for reference in Plan 03 CI integration)
</output>
